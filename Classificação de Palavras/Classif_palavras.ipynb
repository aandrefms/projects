{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import warnings\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, Perceptron, RidgeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "import skopt\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "# ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiros Passos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Este Dataset consiste em um conjunto de comentários feitos em uma loja de livros\n",
    "    - O intuito será de criar um modelo para verificar se o comentário foi positivo ou negativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Criei duas classes para fazer o controle dos \"sentimentos\" positivos, negativos e neutros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "class Sentiment: #created this class to not pass strings into the return\n",
    "    NEGATIVE = 'NEGATIVE'\n",
    "    POSITIVE = 'POSITIVE'\n",
    "    NEUTRAL = 'NEUTRAL'\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        if self.score >= 4.0:\n",
    "            return Sentiment.POSITIVE\n",
    "        elif self.score == 3.0:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else:\n",
    "            return Sentiment.NEGATIVE\n",
    "        \n",
    "class ReviewContainer:\n",
    "    def __init__(self, reviews):\n",
    "        self.reviews = reviews\n",
    "    \n",
    "    def evenly_distributed(self):\n",
    "        negative = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews))\n",
    "        positive = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews))\n",
    "        positive_shrunk = positive [:len(negative)]\n",
    "        self.reviews = negative + positive_shrunk\n",
    "        random.shuffle(self.reviews)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_name = './input/words_alg/sentiment/books_small_10000.json'\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line) #using this i'll be able to transform in a dictionary\n",
    "        reviews.append(Review(review['reviewText'], review['overall']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Categoria</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEGATIVE</th>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEUTRAL</th>\n",
       "      <td>978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POSITIVE</th>\n",
       "      <td>8378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "Categoria      \n",
       "NEGATIVE    644\n",
       "NEUTRAL     978\n",
       "POSITIVE   8378"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'text': [x.text for x in reviews], 'Categoria' : [y.sentiment for y in reviews]\n",
    "                  })\n",
    "df.groupby('Categoria').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Como podemos ver, há muita discrepância nos valores dos 'sentimentos'.\n",
    "- Para resolver isso, usarei um container para nivelar os valores absolutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer #give more value to specific kind of words\n",
    "#Container\n",
    "cont = ReviewContainer(reviews)\n",
    "cont.evenly_distributed()\n",
    "df = pd.DataFrame({'text': [x.text for x in cont.reviews], 'Categoria' : [y.sentiment for y in cont.reviews]\n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Categoria</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEGATIVE</th>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POSITIVE</th>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "Categoria      \n",
       "NEGATIVE    644\n",
       "POSITIVE    644"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.groupby('Categoria').count()\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAJNCAYAAACiKZ1IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAd+ElEQVR4nO3df/Bl9V3f8ddbUDQ/NGAWygAKpqsGoiFxpbZpUyOOwWoFNVRStaiMjFNs00y1glPHOCOamUysdjS1jJqsbRpEE4WmNkpXkxiNIUtCJEAom5DABoQ1/oxGEsi7f3zP2utm1/3ujy/7Zr+Px8zOvedzP+fcz3dn4M5zz7nnW90dAAAAZvq0Y70AAAAADky0AQAADCbaAAAABhNtAAAAg4k2AACAwUQbAADAYCce6wUkydOf/vQ+++yzj/UyAAAAjolbb731j7p7y/5eGxFtZ599dnbu3HmslwEAAHBMVNWHDvSayyMBAAAGE20AAACDiTYAAIDBRBsAAMBgog0AAGAw0QYAADCYaAMAABhMtAEAAAwm2gAAAAYTbQAAAIOJNgAAgMFEGwAAwGCiDQAAYDDRBgAAMJhoAwAAGEy0AQAADCbaAAAABhNtAAAAg4k2AACAwUQbAADAYKINAABgMNEGAAAwmGgDAAAYTLQBAAAMduKxXsATycN3vOdYLwHgCefU8559rJdwXPnSZzzvWC8B4AnlD97/u8d6CUfMmTYAAIDBRBsAAMBgog0AAGAw0QYAADCYaAMAABhMtAEAAAwm2gAAAAYTbQAAAIOJNgAAgMFEGwAAwGCiDQAAYDDRBgAAMJhoAwAAGEy0AQAADCbaAAAABhNtAAAAg4k2AACAwUQbAADAYKINAABgMNEGAAAwmGgDAAAYTLQBAAAMJtoAAAAGE20AAACDiTYAAIDBRBsAAMBgog0AAGAw0QYAADCYaAMAABhMtAEAAAy2rmirqqdV1a9U1fuq6q6q+odVdUpV3VxV9yyPJ6/Mv6aqdlXV3VX1wo1bPgAAwPFtvWfafirJm7r7i5M8O8ldSa5OsqO7tybZsWynqs5NclmS85JclORVVXXC0V44AADAZnDQaKuqz07y/CQ/nyTd/fHu/tMkFyfZvkzbnuSS5fnFSa7v7ke6+94ku5JccHSXDQAAsDms50zbFyTZk+TVVfXuqvq5qnpyktO6+8EkWR5PXeafkeT+lf13L2MAAAAcovVE24lJnpvkv3T3c5L8ZZZLIQ+g9jPWnzKp6sqq2llVO/fs2bOuxQIAAGw264m23Ul2d/c7lu1fyVrEPVRVpyfJ8vjwyvyzVvY/M8kD+x60u6/r7m3dvW3Lli2Hu34AAIDj2kGjrbv/MMn9VfVFy9CFSe5MclOSy5exy5PcuDy/KcllVXVSVZ2TZGuSW47qqgEAADaJE9c5798keW1VfUaSDyT5zqwF3w1VdUWS+5JcmiTdfUdV3ZC1sHs0yVXd/dhRXzkAAMAmsK5o6+7bkmzbz0sXHmD+tUmuPfxlAQAAkKz/97QBAABwDIg2AACAwUQbAADAYKINAABgMNEGAAAwmGgDAAAYTLQBAAAMJtoAAAAGE20AAACDiTYAAIDBRBsAAMBgog0AAGAw0QYAADCYaAMAABhMtAEAAAwm2gAAAAYTbQAAAIOJNgAAgMFEGwAAwGCiDQAAYDDRBgAAMJhoAwAAGEy0AQAADCbaAAAABhNtAAAAg4k2AACAwUQbAADAYKINAABgMNEGAAAwmGgDAAAYTLQBAAAMJtoAAAAGE20AAACDiTYAAIDBRBsAAMBgog0AAGAw0QYAADCYaAMAABhMtAEAAAwm2gAAAAYTbQAAAIOJNgAAgMFEGwAAwGCiDQAAYDDRBgAAMJhoAwAAGEy0AQAADCbaAAAABhNtAAAAg4k2AACAwUQbAADAYKINAABgMNEGAAAwmGgDAAAYTLQBAAAMJtoAAAAGE20AAACDiTYAAIDBRBsAAMBgog0AAGAw0QYAADCYaAMAABhMtAEAAAwm2gAAAAYTbQAAAIOJNgAAgMFEGwAAwGCiDQAAYDDRBgAAMJhoAwAAGEy0AQAADCbaAAAABltXtFXVB6vq9qq6rap2LmOnVNXNVXXP8njyyvxrqmpXVd1dVS/cqMUDAAAc7w7lTNsLuvv87t62bF+dZEd3b02yY9lOVZ2b5LIk5yW5KMmrquqEo7hmAACATeNILo+8OMn25fn2JJesjF/f3Y90971JdiW54AjeBwAAYNNab7R1kt+sqlur6spl7LTufjBJlsdTl/Ezkty/su/uZQwAAIBDdOI65z2vux+oqlOT3FxV7/s75tZ+xvpTJq3F35VJ8nmf93nrXAYAAMDmsq4zbd39wPL4cJJfzdrljg9V1elJsjw+vEzfneSsld3PTPLAfo55XXdv6+5tW7ZsOfyfAAAA4Dh20GirqidX1VP3Pk/yNUnem+SmJJcv0y5PcuPy/KYkl1XVSVV1TpKtSW452gsHAADYDNZzeeRpSX61qvbO/x/d/aaqemeSG6rqiiT3Jbk0Sbr7jqq6IcmdSR5NclV3P7YhqwcAADjOHTTauvsDSZ69n/GPJLnwAPtcm+TaI14dAADAJnckt/wHAABgg4k2AACAwUQbAADAYKINAABgMNEGAAAwmGgDAAAYTLQBAAAMJtoAAAAGE20AAACDiTYAAIDBRBsAAMBgog0AAGAw0QYAADCYaAMAABhMtAEAAAwm2gAAAAYTbQAAAIOJNgAAgMFEGwAAwGCiDQAAYDDRBgAAMJhoAwAAGEy0AQAADCbaAAAABhNtAAAAg4k2AACAwUQbAADAYKINAABgMNEGAAAwmGgDAAAYTLQBAAAMJtoAAAAGE20AAACDiTYAAIDBRBsAAMBgog0AAGAw0QYAADCYaAMAABhMtAEAAAwm2gAAAAYTbQAAAIOJNgAAgMFEGwAAwGCiDQAAYDDRBgAAMJhoAwAAGEy0AQAADCbaAAAABhNtAAAAg4k2AACAwUQbAADAYKINAABgMNEGAAAwmGgDAAAYTLQBAAAMJtoAAAAGE20AAACDiTYAAIDBRBsAAMBgog0AAGAw0QYAADCYaAMAABhMtAEAAAwm2gAAAAYTbQAAAIOJNgAAgMFEGwAAwGCiDQAAYDDRBgAAMJhoAwAAGEy0AQAADLbuaKuqE6rq3VX1xmX7lKq6uaruWR5PXpl7TVXtqqq7q+qFG7FwAACAzeBQzrS9JMldK9tXJ9nR3VuT7Fi2U1XnJrksyXlJLkryqqo64egsFwAAYHNZV7RV1ZlJvi7Jz60MX5xk+/J8e5JLVsav7+5HuvveJLuSXHBUVgsAALDJrPdM208m+Q9JPrkydlp3P5gky+Opy/gZSe5fmbd7GQMAAOAQHTTaqurrkzzc3beu85i1n7Hez3GvrKqdVbVzz5496zw0AADA5rKeM23PS/INVfXBJNcn+aqq+u9JHqqq05NkeXx4mb87yVkr+5+Z5IF9D9rd13X3tu7etmXLliP4EQAAAI5fB4227r6mu8/s7rOzdoOR3+rub0tyU5LLl2mXJ7lxeX5Tksuq6qSqOifJ1iS3HPWVAwAAbAInHsG+L09yQ1VdkeS+JJcmSXffUVU3JLkzyaNJrurux454pQAAAJvQIUVbd785yZuX5x9JcuEB5l2b5NojXBsAAMCmdyi/pw0AAIDHmWgDAAAYTLQBAAAMJtoAAAAGE20AAACDiTYAAIDBRBsAAMBgog0AAGAw0QYAADCYaAMAABhMtAEAAAwm2gAAAAYTbQAAAIOJNgAAgMFEGwAAwGCiDQAAYDDRBgAAMJhoAwAAGEy0AQAADCbaAAAABhNtAAAAg4k2AACAwUQbAADAYKINAABgMNEGAAAwmGgDAAAYTLQBAAAMJtoAAAAGE20AAACDiTYAAIDBRBsAAMBgog0AAGAw0QYAADCYaAMAABhMtAEAAAwm2gAAAAYTbQAAAIOJNgAAgMFEGwAAwGCiDQAAYDDRBgAAMJhoAwAAGEy0AQAADCbaAAAABhNtAAAAg4k2AACAwUQbAADAYKINAABgMNEGAAAwmGgDAAAYTLQBAAAMJtoAAAAGE20AAACDiTYAAIDBRBsAAMBgog0AAGAw0QYAADCYaAMAABhMtAEAAAwm2gAAAAYTbQAAAIOJNgAAgMFEGwAAwGCiDQAAYDDRBgAAMJhoAwAAGEy0AQAADCbaAAAABhNtAAAAg4k2AACAwUQbAADAYKINAABgsINGW1V9ZlXdUlXvqao7qupHlvFTqurmqrpneTx5ZZ9rqmpXVd1dVS/cyB8AAADgeLaeM22PJPmq7n52kvOTXFRVX5Hk6iQ7untrkh3Ldqrq3CSXJTkvyUVJXlVVJ2zA2gEAAI57B422XvPRZfPTlz+d5OIk25fx7UkuWZ5fnOT67n6ku+9NsivJBUdz0QAAAJvFur7TVlUnVNVtSR5OcnN3vyPJad39YJIsj6cu089Icv/K7ruXMQAAAA7RuqKtux/r7vOTnJnkgqp61t8xvfZ3iE+ZVHVlVe2sqp179uxZ12IBAAA2m0O6e2R3/2mSN2ftu2oPVdXpSbI8PrxM253krJXdzkzywH6OdV13b+vubVu2bDn0lQMAAGwC67l75Jaqetry/LOSfHWS9yW5Kcnly7TLk9y4PL8pyWVVdVJVnZNka5JbjvK6AQAANoUT1zHn9CTblztAflqSG7r7jVX19iQ3VNUVSe5LcmmSdPcdVXVDkjuTPJrkqu5+bGOWDwAAcHw7aLR19x8kec5+xj+S5MID7HNtkmuPeHUAAACb3CF9pw0AAIDHl2gDAAAYTLQBAAAMJtoAAAAGE20AAACDiTYAAIDBRBsAAMBgog0AAGAw0QYAADCYaAMAABhMtAEAAAwm2gAAAAYTbQAAAIOJNgAAgMFEGwAAwGCiDQAAYDDRBgAAMJhoAwAAGEy0AQAADCbaAAAABhNtAAAAg4k2AACAwUQbAADAYKINAABgMNEGAAAwmGgDAAAYTLQBAAAMJtoAAAAGE20AAACDiTYAAIDBRBsAAMBgog0AAGAw0QYAADCYaAMAABhMtAEAAAwm2gAAAAYTbQAAAIOJNgAAgMFEGwAAwGCiDQAAYDDRBgAAMJhoAwAAGEy0AQAADCbaAAAABhNtAAAAg4k2AACAwUQbAADAYKINAABgMNEGAAAwmGgDAAAYTLQBAAAMJtoAAAAGE20AAACDiTYAAIDBRBsAAMBgog0AAGAw0QYAADCYaAMAABhMtAEAAAwm2gAAAAYTbQAAAIOJNgAAgMFEGwAAwGCiDQAAYDDRBgAAMJhoAwAAGEy0AQAADCbaAAAABhNtAAAAg4k2AACAwUQbAADAYAeNtqo6q6p+u6ruqqo7quoly/gpVXVzVd2zPJ68ss81VbWrqu6uqhdu5A8AAABwPFvPmbZHk/z77n5mkq9IclVVnZvk6iQ7untrkh3LdpbXLktyXpKLkryqqk7YiMUDAAAc7w4abd39YHe/a3n+F0nuSnJGkouTbF+mbU9yyfL84iTXd/cj3X1vkl1JLjjK6wYAANgUDuk7bVV1dpLnJHlHktO6+8FkLeySnLpMOyPJ/Su77V7GAAAAOETrjraqekqS1yf5d93953/X1P2M9X6Od2VV7ayqnXv27FnvMgAAADaVdUVbVX161oLttd39hmX4oao6fXn99CQPL+O7k5y1svuZSR7Y95jdfV13b+vubVu2bDnc9QMAABzX1nP3yEry80nu6u6fWHnppiSXL88vT3LjyvhlVXVSVZ2TZGuSW47ekgEAADaPE9cx53lJvj3J7VV12zL2g0lenuSGqroiyX1JLk2S7r6jqm5IcmfW7jx5VXc/drQXDgAAsBkcNNq6+23Z//fUkuTCA+xzbZJrj2BdAAAA5BDvHgkAAMDjS7QBAAAMJtoAAAAGE20AAACDiTYAAIDBRBsAAMBgog0AAGAw0QYAADCYaAMAABhMtAEAAAwm2gAAAAYTbQAAAIOJNgAAgMFEGwAAwGCiDQAAYDDRBgAAMJhoAwAAGEy0AQAADCbaAAAABhNtAAAAg4k2AACAwUQbAADAYKINAABgMNEGAAAwmGgDAAAYTLQBAAAMJtoAAAAGE20AAACDiTYAAIDBRBsAAMBgog0AAGAw0QYAADCYaAMAABhMtAEAAAwm2gAAAAYTbQAAAIOJNgAAgMFEGwAAwGCiDQAAYDDRBgAAMJhoAwAAGEy0AQAADCbaAAAABhNtAAAAg4k2AACAwUQbAADAYKINAABgMNEGAAAwmGgDAAAYTLQBAAAMJtoAAAAGE20AAACDiTYAAIDBRBsAAMBgog0AAGAw0QYAADCYaAMAABhMtAEAAAwm2gAAAAYTbQAAAIOJNgAAgMFEGwAAwGCiDQAAYDDRBgAAMJhoAwAAGEy0AQAADCbaAAAABhNtAAAAg4k2AACAwUQbAADAYKINAABgsINGW1X9QlU9XFXvXRk7papurqp7lseTV167pqp2VdXdVfXCjVo4AADAZrCeM22vSXLRPmNXJ9nR3VuT7Fi2U1XnJrksyXnLPq+qqhOO2moBAAA2mYNGW3e/Nckf7zN8cZLty/PtSS5ZGb++ux/p7nuT7EpywdFZKgAAwOZzuN9pO627H0yS5fHUZfyMJPevzNu9jAEAAHAYjvaNSGo/Y73fiVVXVtXOqtq5Z8+eo7wMAACA48PhRttDVXV6kiyPDy/ju5OctTLvzCQP7O8A3X1dd2/r7m1btmw5zGUAAAAc3w432m5Kcvny/PIkN66MX1ZVJ1XVOUm2JrnlyJYIAACweZ14sAlV9bokX5nk6VW1O8kPJ3l5khuq6ook9yW5NEm6+46quiHJnUkeTXJVdz+2QWsHAAA47h002rr7xQd46cIDzL82ybVHsigAAADWHO0bkQAAAHAUiTYAAIDBRBsAAMBgog0AAGAw0QYAADCYaAMAABhMtAEAAAwm2gAAAAYTbQAAAIOJNgAAgMFEGwAAwGCiDQAAYDDRBgAAMJhoAwAAGEy0AQAADCbaAAAABhNtAAAAg4k2AACAwUQbAADAYKINAABgMNEGAAAwmGgDAAAYTLQBAAAMJtoAAAAGE20AAACDiTYAAIDBRBsAAMBgog0AAGAw0QYAADCYaAMAABhMtAEAAAwm2gAAAAYTbQAAAIOJNgAAgMFEGwAAwGCiDQAAYDDRBgAAMJhoAwAAGEy0AQAADCbaAAAABhNtAAAAg4k2AACAwUQbAADAYKINAABgMNEGAAAwmGgDAAAYTLQBAAAMJtoAAAAGE20AAACDiTYAAIDBRBsAAMBgog0AAGAw0QYAADCYaAMAABhMtAEAAAwm2gAAAAYTbQAAAIOJNgAAgMFEGwAAwGCiDQAAYDDRBgAAMJhoAwAAGEy0AQAADCbaAAAABhNtAAAAg4k2AACAwUQbAADAYKINAABgMNEGAAAwmGgDAAAYTLQBAAAMJtoAAAAG27Boq6qLquruqtpVVVdv1PsAAAAczzYk2qrqhCQ/k+Rrk5yb5MVVde5GvBcAAMDxbKPOtF2QZFd3f6C7P57k+iQXb9B7AQAAHLc2KtrOSHL/yvbuZQwAAIBDcOIGHbf2M9Z/a0LVlUmuXDY/WlV3b9BaYLN4epI/OtaLAGDT8jnESFX7S5ORPv9AL2xUtO1OctbK9plJHlid0N3XJblug94fNp2q2tnd2471OgDYnHwOwcbZqMsj35lka1WdU1WfkeSyJDdt0HsBAAActzbkTFt3P1pV35vkN5KckOQXuvuOjXgvAACA49lGXR6Z7v71JL++UccHPoXLjQE4lnwOwQap7j74LAAAAI6JjfpOGwAAAEeBaIPHSVV1Vb1yZfv7quply/OXVdWHq+q2lT9PW167oKreXFX3VNW7qup/VdWX7HPs91TV65bn37lyjI9X1e3L85dX1XdU1U9X1VdW1dv3OcaJVfVQVZ1eVa+pqntXjvN7G/33A8Djp6oeW/7//t6q+uWqetIyfmZV3bh85ry/qn5qualcqupJVfXa5XPlvVX1tqp6yvLaR6vqS1Y+N/545XPk/1TV2cs+T66qj1TV5+yznl+rqn+xfE7t2efz8NzH/28IZhFt8Ph5JMk3VdXTD/D6f+ru81f+/GlVnZbkhiQ/2N1bu/u5SX48yTP27lRVz8zaf8vPr6ond/er9x4ja79q4wXL9tUr7/XWJGdW1dkrY1+d5L3d/eCy/f0ra/lHR+HnB2COjy3/f39Wko8n+Z5a+2VWb0jya929NckXJnlKkmuXfV6S5KHu/pJlvyuSfGLvAbv79pXPn5vy/z9Hvnplzl8m+c0kl+wdWwLuHyd54zL0S/t8Ht65EX8B8EQi2uDx82jWvqT90kPY53uTbO/uvznT1d1v6+5fW5nzL5P8t6x9CH7Deg7a3Z9M8stJvmVl+LIkrzuEtQFwfPidJH8/yVcl+evufnWSdPdjWfvM+q7lTNzpST68d6fuvru7HzmM93td1j5z9vrGJG/q7r86zPXDcU+0wePrZ5J8676XhSxeunIpyG8vY+cleddBjvktSX4pax+CLz6EtfzNh2ZVnZTknyV5/crrr1hZz2sP4bgAPEFU1YlJvjbJ7Vn7zLl19fXu/vMk92Ut6n4hyQ9U1dur6kerauthvu2bknxZVX3usr3vPxp+yz6XR37WYb4PHDdEGzyOlg+/X0zyb/fz8urlkS/Y3/5V9Y6ququqfmrZ/vIke7r7Q0l2JHluVZ28zrW8M8lTquqLsvaB/fvd/ScrU1Yvj/zW9f+UADwBfFZV3ZZkZ9ai7OeTVJL93Va8knR335bkC5K8IskpSd65XKJ/SLr741m7fPJFy1cGzs/a1SJ77Xt55McO9T3geLNhv6cNOKCfzNrZs1evY+4dSZ6b5MYk6e5/UFUvSvL1y+svTvLFVfXBZfuzk3xzkp9b51quz9q/cD4zLo0E2Ew+tnz37G9U1R1Z+wxZHfvsJGcleX+SdPdHs/a9tzdU1SezdpXGXYfx/q9L8h+zFoQ3dvcnDjIfNjVn2uBx1t1/nLWbi1yxjuk/k+Q7qmr1RiB77/D1aUkuTfKl3X12d5+d5OIc+iWS35a17zHcdAj7AXD82ZHkSVX1r5Kkqk5I8sokr+nuv6qq5+29mmO5o+S5ST50mO/120m2Jrkq/tEQDkq0wbHxyiT73kXypftcw392d/9h1r6z9uNVtWu59f6Lkvx0kucn+XB3f3jlGG9Ncm5Vnb6eRSx35PqrJL+13NFr1Sv2Wc9nHMbPCcATRHd31m4KcmlV3ZPk/yb56yQ/uEx5RpK3VNXtSd6dtUsrX7+/Y63jvT657Pu5WfvsWrXvd9rcwZhNr9b++wQAAGAiZ9oAAAAGE20AAACDiTYAAIDBRBsAAMBgog0AAGAw0QbAE0ZV/b2qur6q3l9Vd1bVr1fVFx5g7tOq6l8/Tuv6nr2/2woAjja3/AfgCaGqKsnvJdne3T+7jJ2f5Knd/Tv7mX92kjd297M2eF0ndvejG/keAGxuzrQB8ETxgiSf2BtsSdLdtyV5d1XtqKp3VdXtVXXx8vLLkzxj+eW8r0iSqvr+qnpnVf1BVf3I3uNU1Q9V1fuq6uaqel1Vfd8yfn5V/f4y/1er6uRl/M1V9WNV9ZYkL6mql63s893Le7ynql5fVU96PP5yADh+iTYAniieleTW/Yz/dZJv7O7nZi3sXrmclbs6yfu7+/zu/v6q+pokW5NckOT8JF9WVc+vqm1JvjnJc5J8U5JtK8f+xSQ/0N1fmuT2JD+88trTuvufdvcr91nPG7r7y7v72UnuSnLFkf3YAGx2Jx7rBQDAEaokP1ZVz0/yySRnJDltP/O+Zvnz7mX7KVmLuKcmubG7P5YkVfU/l8fPyVqYvWWZvz3JL68c75cOsJ5nVdWPJnna8h6/cXg/FgCsEW0APFHckeRF+xn/1iRbknxZd3+iqj6Y5DP3M6+S/Hh3/9e/NVj10sNcz18eYPw1SS7p7vdU1Xck+crDPD4AJHF5JABPHL+V5KSq+u69A1X15Uk+P8nDS7C9YNlOkr/I2lm0vX4jyXdV1VOWfc+oqlOTvC3JP6+qz1xe+7ok6e4/S/InVfVPlv2/PclbcnBPTfJgVX161oISAI6IM20APCF0d1fVNyb5yaq6OmvfZftgkpcl+c9VtTPJbUnet8z/SFX9blW9N8n/Xr7X9swkb1/7yls+muTbuvudVXVTkvck+VCSnUn+bHnby5P87HIzkQ8k+c51LPWHkrxjOdbt+dvhCACHzC3/Adj0quop3f3RJc7emuTK7n7XsV4XACTOtAFAklxXVedm7btw2wUbAJM40wYAADCYG5EAAAAMJtoAAAAGE20AAACDiTYAAIDBRBsAAMBgog0AAGCw/wc/JGmWH+p6VwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "ax= sns.barplot(x=df1['text'].index, y=df1['text'].values,palette = sns.cubehelix_palette(len(df1.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando transformações no Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ser possível modelar este dataset, preciso primeiramente converter os elementos da coluna 'text' em vetores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = [x.text for x in cont.reviews]\n",
    "y = [y.sentiment for y in cont.reviews]\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer #give more value to specific kind of words\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Primeiro, dividirei o dataset em dois: Train e Test\n",
    "    - Servirá para, ao fazer a modelagem, poder testar o modelo em uma parte do dataset que não foi utilizado para a modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train)=1026; len(test)=262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(262, 10405)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(df)\n",
    "TRAIN_PERC = 0.8\n",
    "ind_train = np.random.rand(N) < TRAIN_PERC\n",
    "train, test = df[ind_train], df[~ind_train]\n",
    "print(f'len(train)={len(train)}; len(test)={len(test)}')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train.text)\n",
    "X_train_counts.shape\n",
    "\n",
    "X_test_counts = count_vect.transform(test.text)\n",
    "X_test_counts.shape\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape\n",
    "\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "X_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aqui inicio o processo de modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dict = {\n",
    "    'LogisticRegression': LogisticRegression,\n",
    "    'MultinomialNB': MultinomialNB,\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier,\n",
    "    'SGDClassifier': SGDClassifier,\n",
    "    'Perceptron': Perceptron,\n",
    "    'RidgeClassifier': RidgeClassifier,\n",
    "    'LinearSVC': LinearSVC,\n",
    "    'RandomForestClassifier': RandomForestClassifier,\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier,\n",
    "    #'MLPClassifier': MLPClassifier,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy gets in 0.1s.\n",
      "Clf=LogisticRegression; Accuracy=0.8740458015267175\n",
      "Accuracy gets in 0.0s.\n",
      "Clf=MultinomialNB; Accuracy=0.8549618320610687\n",
      "Accuracy gets in 0.11s.\n",
      "Clf=DecisionTreeClassifier; Accuracy=0.7099236641221374\n",
      "Accuracy gets in 0.0s.\n",
      "Clf=SGDClassifier; Accuracy=0.8549618320610687\n",
      "Accuracy gets in 0.0s.\n",
      "Clf=Perceptron; Accuracy=0.8320610687022901\n",
      "Accuracy gets in 0.01s.\n",
      "Clf=RidgeClassifier; Accuracy=0.8549618320610687\n",
      "Accuracy gets in 0.01s.\n",
      "Clf=LinearSVC; Accuracy=0.8435114503816794\n",
      "Accuracy gets in 0.17s.\n",
      "Clf=RandomForestClassifier; Accuracy=0.8015267175572519\n",
      "Accuracy gets in 1.32s.\n",
      "Clf=GradientBoostingClassifier; Accuracy=0.7900763358778626\n"
     ]
    }
   ],
   "source": [
    "def get_accuracy(clf, n_estimators=None, max_depth=None, learning_rate=None, max_iter=None):\n",
    "    start = time.time()\n",
    "    text_clf = clf(**params).fit(X_train_tfidf, train.Categoria)\n",
    "    predicted = text_clf.predict(X_test_tfidf)\n",
    "    print(f'Accuracy gets in {round(time.time()-start, 2)}s.')\n",
    "    return np.mean(predicted == test.Categoria)\n",
    "\n",
    "result_dict = {}\n",
    "\n",
    "for clf_str, clf_fn in clf_dict.items():\n",
    "    if clf_str == 'LogisticRegression':\n",
    "        params = {'max_iter': 200}\n",
    "    elif clf_str == 'RandomForestClassifier':\n",
    "        params = {'n_estimators': 50,\n",
    "                  'max_depth': 10}\n",
    "    elif clf_str == 'DecisionTreeClassifier':\n",
    "        params = {'max_depth': 10}\n",
    "    elif clf_str == 'GradientBoostingClassifier':\n",
    "        params = {'n_estimators': 50,\n",
    "                  'learning_rate': 0.1}\n",
    "    else:\n",
    "        params = {}\n",
    "    accuracy = get_accuracy(clf=clf_fn, **params)\n",
    "    result_dict[clf_str] = accuracy\n",
    "    print(f\"Clf={clf_str}; Accuracy={accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': 0.8740458015267175,\n",
       " 'MultinomialNB': 0.8549618320610687,\n",
       " 'SGDClassifier': 0.8549618320610687,\n",
       " 'RidgeClassifier': 0.8549618320610687,\n",
       " 'LinearSVC': 0.8435114503816794,\n",
       " 'Perceptron': 0.8320610687022901,\n",
       " 'RandomForestClassifier': 0.8015267175572519,\n",
       " 'GradientBoostingClassifier': 0.7900763358778626,\n",
       " 'DecisionTreeClassifier': 0.7099236641221374}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict = {\n",
    "    k: v\n",
    "    for k, v in sorted(\n",
    "        result_dict.items(),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "}\n",
    "\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Percebemos aqui valores aceitaveis sem fazer nenhuma optimização, chegando a 87% de precisão com LogisticRegression\n",
    "- Agora, inicio os processos de optimização afim de verificar se existem melhores parametros à serem utilizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_Logistic = [\n",
    "    Integer(100, 400, name='max_iter')\n",
    "]\n",
    "\n",
    "DIM_SVC = [\n",
    "    Real(1e-5, 1, name='tol', prior='log-uniform'),\n",
    "    Real(0.1, 1.5, name='C', prior='log-uniform')\n",
    "]\n",
    "\n",
    "DIM_SGDC = [\n",
    "    Real(1e-5, 1e-2, name='alpha', prior='log-uniform')\n",
    "]\n",
    "\n",
    "DIM_RF = [\n",
    "    Integer(1, 100, name='n_estimators'),\n",
    "    Integer(5, 30, name='max_depth')\n",
    "]\n",
    "\n",
    "DIMS = {\n",
    "    'LogisticRegression': DIM_Logistic,\n",
    "    'LinearSVC': DIM_SVC,\n",
    "    'SGDClassifier': DIM_SGDC,\n",
    "    'RandomForestClassifier': DIM_RF\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(clf_str='LinearSVC'):\n",
    "    \n",
    "    dimensions = DIMS[clf_str]\n",
    "    print(dimensions)\n",
    "    \n",
    "    @use_named_args(dimensions=dimensions)\n",
    "    def fitness(**params):\n",
    "        clf = clf_dict[clf_str](**params)\n",
    "        text_clf = clf.fit(X_train_tfidf, train.Categoria)\n",
    "        predicted = text_clf.predict(X_test_tfidf)\n",
    "        accuracy = np.mean(predicted == test.Categoria)\n",
    "        print(f'accuracy={accuracy} with params={params}')\n",
    "        return -1.0 * accuracy\n",
    "    \n",
    "    res = gp_minimize(func=fitness,\n",
    "                      dimensions=dimensions,\n",
    "                      acq_func='EI', # Expected Improvement.\n",
    "                      n_calls=10,\n",
    "                      random_state=666)\n",
    "    print(f'best accuracy={-1.0 * res.fun} with {res.x}')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start optimizaton for LogisticRegression\n",
      "[Integer(low=100, high=400, prior='uniform', transform='identity')]\n",
      "accuracy=0.8740458015267175 with params={'max_iter': 131}\n",
      "accuracy=0.8740458015267175 with params={'max_iter': 163}\n",
      "accuracy=0.8740458015267175 with params={'max_iter': 139}\n",
      "accuracy=0.8740458015267175 with params={'max_iter': 325}\n",
      "accuracy=0.8740458015267175 with params={'max_iter': 201}\n",
      "accuracy=0.8740458015267175 with params={'max_iter': 173}\n",
      "accuracy=0.8740458015267175 with params={'max_iter': 178}\n",
      "accuracy=0.8740458015267175 with params={'max_iter': 184}\n",
      "accuracy=0.8740458015267175 with params={'max_iter': 239}\n",
      "accuracy=0.8740458015267175 with params={'max_iter': 170}\n",
      "best accuracy=0.8740458015267175 with [131]\n",
      "start optimizaton for LinearSVC\n",
      "[Real(low=1e-05, high=1, prior='log-uniform', transform='identity'), Real(low=0.1, high=1.5, prior='log-uniform', transform='identity')]\n",
      "accuracy=0.8664122137404581 with params={'tol': 3.2590317060358435e-05, 'C': 0.17723383193111547}\n",
      "accuracy=0.8473282442748091 with params={'tol': 4.414527342912078e-05, 'C': 0.7628816961239331}\n",
      "accuracy=0.8664122137404581 with params={'tol': 0.00047845573514670206, 'C': 0.19380701478072257}\n",
      "accuracy=0.8625954198473282 with params={'tol': 0.00019924054402314126, 'C': 0.21413112813185142}\n",
      "accuracy=0.8664122137404581 with params={'tol': 0.0020616191023600985, 'C': 0.1881485055702094}\n",
      "accuracy=0.8473282442748091 with params={'tol': 0.06844174269781644, 'C': 0.9211783872460952}\n",
      "accuracy=0.8625954198473282 with params={'tol': 0.0009713622714043581, 'C': 0.23559366117301345}\n",
      "accuracy=0.8473282442748091 with params={'tol': 5.9918414788335004e-05, 'C': 0.7310856330548163}\n",
      "accuracy=0.8435114503816794 with params={'tol': 0.045496473405299345, 'C': 1.0207519927651907}\n",
      "accuracy=0.8435114503816794 with params={'tol': 0.06871660898768098, 'C': 1.3215606065550862}\n",
      "best accuracy=0.8664122137404581 with [3.2590317060358435e-05, 0.17723383193111547]\n",
      "start optimizaton for SGDClassifier\n",
      "[Real(low=1e-05, high=0.01, prior='log-uniform', transform='identity')]\n",
      "accuracy=0.851145038167939 with params={'alpha': 2.031669923181096e-05}\n",
      "accuracy=0.8473282442748091 with params={'alpha': 4.3052494479948036e-05}\n",
      "accuracy=0.8435114503816794 with params={'alpha': 2.4374208772219314e-05}\n",
      "accuracy=0.8625954198473282 with params={'alpha': 0.0017823444328076245}\n",
      "accuracy=0.851145038167939 with params={'alpha': 0.0001018368738042549}\n",
      "accuracy=0.8129770992366412 with params={'alpha': 5.4078987915686634e-05}\n",
      "accuracy=0.8320610687022901 with params={'alpha': 6.020417803091192e-05}\n",
      "accuracy=0.8282442748091603 with params={'alpha': 6.974377878633414e-05}\n",
      "accuracy=0.8473282442748091 with params={'alpha': 0.00024463864226893333}\n",
      "accuracy=0.8282442748091603 with params={'alpha': 5.014212529363377e-05}\n",
      "best accuracy=0.8625954198473282 with [0.0017823444328076245]\n",
      "start optimizaton for RandomForestClassifier\n",
      "[Integer(low=1, high=100, prior='uniform', transform='identity'), Integer(low=5, high=30, prior='uniform', transform='identity')]\n",
      "accuracy=0.7442748091603053 with params={'n_estimators': 11, 'max_depth': 10}\n",
      "accuracy=0.7404580152671756 with params={'n_estimators': 14, 'max_depth': 24}\n",
      "accuracy=0.7900763358778626 with params={'n_estimators': 34, 'max_depth': 11}\n",
      "accuracy=0.7366412213740458 with params={'n_estimators': 27, 'max_depth': 12}\n",
      "accuracy=0.7900763358778626 with params={'n_estimators': 47, 'max_depth': 11}\n",
      "accuracy=0.8129770992366412 with params={'n_estimators': 77, 'max_depth': 25}\n",
      "accuracy=0.7862595419847328 with params={'n_estimators': 40, 'max_depth': 13}\n",
      "accuracy=0.7824427480916031 with params={'n_estimators': 16, 'max_depth': 23}\n",
      "accuracy=0.8053435114503816 with params={'n_estimators': 73, 'max_depth': 26}\n",
      "accuracy=0.7862595419847328 with params={'n_estimators': 77, 'max_depth': 29}\n",
      "best accuracy=0.8129770992366412 with [77, 25]\n"
     ]
    }
   ],
   "source": [
    "res_dict = {}\n",
    "for clf_str, clf_dim in DIMS.items():\n",
    "    print(f'start optimizaton for {clf_str}')\n",
    "    res = optimize(clf_str=clf_str)\n",
    "    res_dict[clf_str] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf=LogisticRegression\n",
      "best accuracy=0.8740458015267175\n",
      "best hyperparameters={'max_iter': 131}\n",
      "\n",
      "clf=LinearSVC\n",
      "best accuracy=0.8664122137404581\n",
      "best hyperparameters={'tol': 3.2590317060358435e-05, 'C': 0.17723383193111547}\n",
      "\n",
      "clf=SGDClassifier\n",
      "best accuracy=0.8625954198473282\n",
      "best hyperparameters={'alpha': 0.0017823444328076245}\n",
      "\n",
      "clf=RandomForestClassifier\n",
      "best accuracy=0.8129770992366412\n",
      "best hyperparameters={'n_estimators': 77, 'max_depth': 25}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf_str, res in res_dict.items():\n",
    "    hyperparameters_label = [hp.name for hp in DIMS[clf_str]]\n",
    "    best_hyperparameters = dict(zip(hyperparameters_label, res.x))\n",
    "    print(f'clf={clf_str}\\nbest accuracy={-res.fun}\\nbest hyperparameters={best_hyperparameters}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- O objetivo desse Kernel foi analisar e construir um modelo capaz de prever o padrão de texto em: descrições positivas e negativas.\n",
    "- Este estudo pode se reproduzido em websites, e-commerces, blogs, etc afim de verificar a quantidade de comentários positivos e negativos de determinado produto ou seção\n",
    "- Foi alcançado um percentual de 87.40% de precisão com apenas 1288 linhas de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
